{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopo del notebook: testare la rete su Car Brand Logos\n",
    "\n",
    "#### Costanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# percorso dove ho salvato il modello\n",
    "SAVE_PATH = 'trained/bright_res_v3/bright_res_v3_best.pth'\n",
    "# definisce se usare la ResNet18 (true) o LeNet5 (false)\n",
    "using_res = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rcGlq6D9pJP"
   },
   "source": [
    "#### Percorso dove trovare test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_path = 'data/car_brand_logos/Test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Resize, ToPILImage, CenterCrop, Normalize, Compose\n",
    "from torchvision.transforms.functional import to_grayscale, to_tensor, rotate, hflip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "from PIL.features import pilinfo\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D3dUDXh9pJX"
   },
   "source": [
    "### Funzioni per recuperare i dati\n",
    "\n",
    " - getLabelList(percorso del dataset): ritorna una Series costituita da indice numerico a cui associa l'immagine (nome) e la sua label (valore numerico)\n",
    " - getImgPool(percorso del dataset): ritorna una Series costituita da indice numerico a cui associa il percorso assoluto dell'immagine, la label (valore numerico) e la corrisponde classe (stringa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qeg4aPqp9pJX"
   },
   "outputs": [],
   "source": [
    "def getLabelList(path):\n",
    "    only_dirs = [ name for name in os.listdir(path) if \n",
    "                 os.path.isdir(os.path.join(path, name)) ]\n",
    "\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    \n",
    "    for d in only_dirs:\n",
    "        new_path = path + d\n",
    "        label = only_dirs.index(d)\n",
    "        # print(len(os.listdir(new_path)))\n",
    "        for img in [ name for name in os.listdir(new_path) ]:\n",
    "            ret[index] = [img, label]\n",
    "            index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TpIgryw9pJY"
   },
   "outputs": [],
   "source": [
    "def getImgPool(path):\n",
    "    only_dirs = [ name for name in os.listdir(path) if \n",
    "                 os.path.isdir(os.path.join(path, name)) ]\n",
    "\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    \n",
    "    for d in only_dirs:\n",
    "        new_path = path + d\n",
    "        label = only_dirs.index(d)\n",
    "        for img in [ name for name in os.listdir(new_path) ]:\n",
    "            abs_path = new_path + '/' + img\n",
    "            ret[index] = [abs_path, label, d]\n",
    "            index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhMcw_pl9pJZ",
    "tags": []
   },
   "source": [
    "## Creazione della struttura dataset (contenitore di immagini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANyx-fNV9pJa",
    "tags": []
   },
   "source": [
    "### LeNet5\n",
    "Caratteristiche: immagini in bianco e nero, augmentation usate: rotazione e specchiamento asse y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kogV1IN89pJa"
   },
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    class CustomImageDataset(Dataset):\n",
    "        def __init__(self, path_labels, transform=None, target_transform=None, use_aug=True):\n",
    "            self.img_labels = getLabelList(path_labels)\n",
    "            self.images = getImgPool(path_labels)\n",
    "            self.transform = transform\n",
    "            self.target_transform = target_transform\n",
    "            self.use_aug = use_aug\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.img_labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            try: \n",
    "                image = Image.open(self.images.loc[idx][0])\n",
    "            except Exception:\n",
    "                print('Found error at {} in position {}'.format(self.images.loc[idx][0], idx))\n",
    "            image = ToTensor()(image)\n",
    "            \n",
    "            if image.shape[0] >= 3: #trasformo l'immagine in bianco e nero\n",
    "                image = to_tensor(to_grayscale(ToPILImage()(image), num_output_channels=1))\n",
    "            else: #già in bianco e nero, converto al Tensor \n",
    "                image = to_tensor(ToPILImage()(image))\n",
    "\n",
    "            image = Resize((300, 300))(image)\n",
    "            \n",
    "            #parte di data augmentation\n",
    "            if self.use_aug:\n",
    "                fr = random.choices([0,1],[0.2,0.8])[0] # rotazione (80% probabilità di capitare)\n",
    "                if fr == 1: \n",
    "                    angle = torch.randint(40, size=(1,)).item() - 20 \n",
    "                    image = rotate(image, angle)\n",
    "\n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # specchiamento asse y (80% probabilità di capitare)\n",
    "                if fr == 1: \n",
    "                    image = hflip(image)\n",
    "            label = self.img_labels.loc[idx][1]\n",
    "\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTutNs0v9pJb",
    "tags": []
   },
   "source": [
    "### ResNet18\n",
    "Caratteristiche: immagini a colori, augmentation usate: cambio luminosità, rotazione, \n",
    "specchiamento asse y, traslazione su entrambi gli assi tra 100 e -100px, rumore gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUp7Z8IH9pJb"
   },
   "outputs": [],
   "source": [
    "if using_res:\n",
    "    class CustomImageDataset(Dataset):\n",
    "        def __init__(self, path_labels, transform=None, target_transform=None, use_aug=True):\n",
    "            self.img_labels = getLabelList(path_labels)\n",
    "            self.images = getImgPool(path_labels)\n",
    "            self.transform = transform\n",
    "            self.target_transform = target_transform\n",
    "            self.use_aug = use_aug\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.img_labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            try: \n",
    "                image = Image.open(self.images.loc[idx][0])\n",
    "                if Image.MIME[image.format] == 'image/png': #formato errato\n",
    "                        image = convertPNGImage(self.images.loc[idx][0], 'PNG')\n",
    "            except Exception:\n",
    "                print('Found error at {} in position {}'.format(self.images.loc[idx][0], idx))\n",
    "                \n",
    "            image = ToTensor()(image)\n",
    "            \n",
    "            if image.shape[0] != 3: #converto le immagini in bianco e nero e RGBA in RGB\n",
    "                image = ToPILImage()(image).convert('RGB')  \n",
    "            else: #immagine già RGB\n",
    "                image = ToPILImage()(image)\n",
    "                \n",
    "            preprocess = Compose([\n",
    "                Resize(300),\n",
    "                CenterCrop(300),\n",
    "                ToTensor(),\n",
    "            ])\n",
    "            image = preprocess(image)\n",
    "            \n",
    "            #parte di data augmentation\n",
    "            if self.use_aug:\n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # cambio luminosita (50% probabilità di capitare)\n",
    "                if fr == 1:\n",
    "                    num = 0.5 + random.random()\n",
    "                    image = adjust_brightness(image, num)\n",
    "                \n",
    "                fr = random.choices([0,1],[0.2,0.8])[0] # rotazione (80% probabilità di capitare)\n",
    "                if fr == 1: \n",
    "                    angle = torch.randint(40, size=(1,)).item() - 20\n",
    "                    image = rotate(image, angle)\n",
    "\n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # specchiamento asse y (50% probabilità di capitare)\n",
    "                if fr == 1: \n",
    "                    image = hflip(image)\n",
    "                    \n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # traslazione (50% probabilità di capitare)\n",
    "                if fr == 1:\n",
    "                    trX = torch.randint(200, size=(1,)).item() - 100\n",
    "                    trY = torch.randint(200, size=(1,)).item() - 100\n",
    "                    image = affine(image, angle=0, translate=(trX, trY), scale=1, shear=0)\n",
    "                    \n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # rumore gaussiano (50% probabilità di capitare)\n",
    "                if fr == 1:\n",
    "                    gauss_noise = np.random.normal(0, 0.4, (image.shape[1], image.shape[2]))\n",
    "                    image = image + gauss_noise\n",
    "            \n",
    "            preprocess2 = Compose([ # secondo preprocess dell'immagine per evitare problemi con il cambio luminosità\n",
    "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            image = preprocess2(image)\n",
    "            \n",
    "            label = self.img_labels.loc[idx][1]\n",
    "\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8HbY1Gw9pJc"
   },
   "source": [
    "### Creazione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "nd4q0jbl9pJc",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "cefec1a1-f904-4a12-aca6-e5a418ee8a49"
   },
   "outputs": [],
   "source": [
    "test_data = CustomImageDataset(path_labels=test_path, transform=ToTensor(), target_transform=ToTensor(), use_aug=False)\n",
    "\n",
    "print (f'N° immagini nel test dataset: {test_data.__len__()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "upqv1Vnx9pJd",
    "outputId": "2cf942e9-6df7-4b04-976e-63c378930f41"
   },
   "outputs": [],
   "source": [
    "#verifica caricamento delle immagini\n",
    "only_dirs = [ name for name in os.listdir(test_path) if \n",
    "                 os.path.isdir(os.path.join(test_path, name)) ]\n",
    "\n",
    "diz = {}\n",
    "nocl=0 # numero di classi\n",
    "for d in only_dirs:\n",
    "    diz[nocl] = d\n",
    "    nocl+=1\n",
    "\n",
    "figure = plt.figure(figsize=(12, 12))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(test_data), size=(1,)).item() \n",
    "    img, label = test_data[sample_idx]\n",
    "    if using_res: # rimuovo effetti normalizzazione (cattiva visualizzazione delle immagini)\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "    img = torch.clamp(img, 0, 1) # rimuovo effetti rumore gaussiano\n",
    "    \n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(diz[label])\n",
    "    plt.axis(\"off\")\n",
    "    if not using_res:\n",
    "        plt.imshow(img.squeeze(), cmap='gray') # visualizzazione lenet\n",
    "    else:\n",
    "        plt.imshow(img.permute(1,2,0)) # visualizzazione resnet\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuNxVR_K9pJe"
   },
   "source": [
    "## Creazione dataloader (richiede immagini al dataset, producendo i batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "0Dn-jlHc9pJf",
    "outputId": "90962960-d983-4657-a7dc-1029fecb8f5c"
   },
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "0Dn-jlHc9pJf",
    "outputId": "90962960-d983-4657-a7dc-1029fecb8f5c"
   },
   "outputs": [],
   "source": [
    "#dataloader test\n",
    "images, labels = next(iter(test_dl)) #prendo un batch\n",
    "print(f\"Feature batch shape: {images.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")\n",
    "# prendo prima immagine e label dal batch\n",
    "img = images[0]\n",
    "label = labels[0]\n",
    "if not using_res:\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "else:\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "plt.show()\n",
    "print(f\"Classe: {diz[label.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP2Ccger9pJf"
   },
   "source": [
    "## Definizione della rete neurale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANyx-fNV9pJa",
    "tags": []
   },
   "source": [
    "### LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loury7rK9pJg"
   },
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 6, 5)  # 1 indica il numero di canali dell'immagine (1 - bianco e nero)\n",
    "                                             # 6 indica i canali di uscita\n",
    "                                             # 5 indica la dimensione del filtro\n",
    "                                             # DEFAULT: passo = 1, padding = 0\n",
    "            self.pool = nn.MaxPool2d(2, 2) # finestra di pooling grande 2x2 (quindi dimezza altezza e larghezza dell'immagine)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)        \n",
    "            self.fc_layer1 = nn.Linear(16 * 72 * 72, 120)        \n",
    "            self.fc_layer2 = nn.Linear(120, 84)\n",
    "            self.fc_layer3 = nn.Linear(84, nocl) # nocl indica il numero di classi (8 qui)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc_layer1(x))\n",
    "            x = F.relu(self.fc_layer2(x))\n",
    "            x = self.fc_layer3(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANyx-fNV9pJa",
    "tags": []
   },
   "source": [
    "### Scelta architettura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    loaded = Net()\n",
    "else:\n",
    "    loaded = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento del modello salvato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.load_state_dict(torch.load(SAVE_PATH))\n",
    "loaded.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esempio di predizioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_dl)) # prendo un batch\n",
    "\n",
    "n_imgs = len(images)\n",
    "\n",
    "preds = loaded(images)\n",
    "_, best_pred = torch.max(preds.data, 1)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(25,4), nrows=1, ncols=n_imgs)\n",
    "\n",
    "for i in range(n_imgs):\n",
    "    if using_res:\n",
    "        images[i] = images[i] * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "    axs[i].imshow(images[i].permute(1,2,0).cpu(), cmap='gray')\n",
    "    axs[i].set_title('Vero: {}\\nPredetto: {}'.format(diz[labels[i].item()], diz[best_pred[i].item()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo dell'accuratezza su tutto il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conto predizioni di tutte le predizioni\n",
    "correct_pred = {classname: 0 for classname in diz}\n",
    "total_pred = {classname: 0 for classname in diz}\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for data in test_dl:\n",
    "    images, labels = data\n",
    "    outputs = loaded(images)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    # conto le predizioni corrette\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label == prediction:\n",
    "            correct_pred[label.item()] += 1\n",
    "        total_pred[label.item()] += 1\n",
    "        y_true.append(label)\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "# stampa accuratezza per ogni classe\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuratezza della classe: {diz[classname]} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stampa report classificazioni\n",
    "print(classification_report(y_true, y_pred, target_names=diz.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createConfusionMatrix(loader, netw):\n",
    "    y_pred = [] # dove salvo predizioni\n",
    "    y_true = [] # dove salvo classi\n",
    "\n",
    "    # ciclo sul dataloader\n",
    "    for inputs, labels in loader:\n",
    "        output = netw(inputs)\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.numpy()\n",
    "        y_pred.extend(output)  # salvo predizioni\n",
    "\n",
    "        labels = labels.data.numpy()\n",
    "        y_true.extend(labels)  # salvo classi\n",
    "\n",
    "    # lista di classi\n",
    "    classes = diz.values()\n",
    "\n",
    "    # costruisco la matrice di confusione\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    # normalizzo (valori tra 0 e 1)\n",
    "    cmn = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # creo dataframe e costruisco matrice (immagine) \n",
    "    df_cm = pd.DataFrame(cmn, index=[i for i in classes],\n",
    "                         columns=[i for i in classes])\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='jpeg')\n",
    "    buf.seek(0)\n",
    "    im = Image.open(buf)\n",
    "    im = ToTensor()(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessita di circa 30s per produrre la matrice\n",
    "plt.figure(figsize=(8, 8), dpi=125)\n",
    "plt.imshow(createConfusionMatrix(test_dl, loaded).permute(1,2,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
