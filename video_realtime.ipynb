{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#where to load the net to use\n",
    "NN_PATH = 'trained/scheduler_resnet/new_res18_25_best.pth'\n",
    "LABELS_PATH = 'data/images_scraped/'\n",
    "\n",
    "using_res = True\n",
    "ssz=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Resize, ToPILImage, CenterCrop, Normalize, Compose\n",
    "from torchvision.transforms.functional import to_grayscale, to_tensor, rotate, hflip, crop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "from PIL.features import pilinfo\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "import cv2\n",
    "from numpy import asarray\n",
    "import copy\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU compute available:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU compute available: \", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            #conv1: 1 input image channel (image channel, 1 gray, 3 rgb), 6 output channels (depth [K]), 5x5 square convolution kernel, DEFAULT: stride = 1,1, padding = 0\n",
    "            self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)        \n",
    "            self.fc_layer1 = nn.Linear(16 * 72 * 72, 120)        \n",
    "            self.fc_layer2 = nn.Linear(120, 84)\n",
    "            self.fc_layer3 = nn.Linear(84, nocl) # nocl is the num of classes\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Max pooling over a (2, 2) window\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            #print ('conv1', x.shape)\n",
    "            # If the size is a square, you can specify with a single number\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "            #print ('flatten', x.shape)\n",
    "            x = F.relu(self.fc_layer1(x))\n",
    "            x = F.relu(self.fc_layer2(x))\n",
    "            x = self.fc_layer3(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the network on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\eliad/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "if not using_res:\n",
    "    loaded = Net()\n",
    "else:\n",
    "    loaded = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded.load_state_dict(torch.load(NN_PATH))\n",
    "loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['hyundai', 'lexus', 'mazda', 'mercedes', 'opel', 'skoda', 'toyota', 'volkswagen'])\n"
     ]
    }
   ],
   "source": [
    "only_dirs = [ name for name in os.listdir(LABELS_PATH) if \n",
    "                 os.path.isdir(os.path.join(LABELS_PATH, name)) ]\n",
    "\n",
    "diz = {} #diz [key=LABEL_INDEX, value=LABEL_NAME]\n",
    "diz2 = {} #diz2 [key=LABEL_INDEX, value=PROB_PREDICTION]\n",
    "nocl=0 #num of classes\n",
    "for d in only_dirs:\n",
    "    diz[nocl] = d\n",
    "    diz2[nocl] = 0\n",
    "    nocl+=1\n",
    "    \n",
    "print(diz.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(im, x0, y0):\n",
    "    cropped = crop(im, y0, x0, ssz, ssz)\n",
    "    actions = Compose([\n",
    "                Resize(300),\n",
    "                CenterCrop(300),\n",
    "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "    return actions(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_drawbar(frame):\n",
    "    #producing predictions and sort to get probabilities\n",
    "    target_frame = frame[None, :] #adding 1 dim to simulate batch\n",
    "    out = loaded(target_frame)\n",
    "    _, best_pred = torch.max(out.data, 1)\n",
    "    perc = torch.nn.functional.softmax(out, dim=1)[0] * 100    \n",
    "    _, indices = torch.sort(out, descending=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,16), nrows=1, ncols=1)\n",
    "    \n",
    "    #creating barplot\n",
    "    plt.ylim(0, 100)\n",
    "    for idx in indices[0][:8]:\n",
    "        diz2[idx.item()] = perc[idx].item()\n",
    "\n",
    "    bars = plt.bar( diz.values(), diz2.values(), width=0.7, color='red')\n",
    "    \n",
    "    # plt.rc('axes', labelsize=20)\n",
    "    # plt.rc('xtick', labelsize=20)\n",
    "    # plt.rc('ytick', labelsize=20)\n",
    "    \n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    ax.tick_params(axis='both', labelsize=25)\n",
    "    ax.set_xlabel('labels', fontsize=30)\n",
    "    ax.set_ylabel('accuracy [%]', fontsize=30)\n",
    "    ax.set_title('predictions', fontsize=40)\n",
    "    ax.yaxis.set_ticks(np.linspace(0,100,21))\n",
    "    ax.grid(axis='y')\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='jpeg')\n",
    "    buf.seek(0)\n",
    "    frame = Image.open(buf)\n",
    "    plt.close()\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Car logo realtime demo.')\n",
    "parser.add_argument('--fullscreen', action='store_true', help='run in fullscreen')\n",
    "# args = parser.parse_args() #removed since conflicts with jupyter console\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "# Setup acquisition\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.release()\n",
    "\n",
    "windowname=\"Car logo Live Demo\"\n",
    "cv2.namedWindow(windowname, cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.moveWindow(windowname, 0, 0)\n",
    "cv2.setWindowProperty(windowname, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# for i in range(1):\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    im = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    im = cv2.flip(im, 1)\n",
    "    \n",
    "    h, w = im.shape[0:2]\n",
    "    x0 = w // 2 - ssz // 2\n",
    "    y0 = h // 2 - ssz // 2\n",
    "    \n",
    "    \n",
    "    im_tensor = to_tensor(np.array(im))\n",
    "    rect = patches.Rectangle((x0, y0), ssz, ssz, linewidth=1,\n",
    "                         edgecolor='r', facecolor=\"none\")\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(24, 18), nrows=1, ncols=3, gridspec_kw={'width_ratios': [10,4,10]})\n",
    "    plt.axis(\"off\")\n",
    "    plt.rc('axes', titlesize=35)\n",
    "    \n",
    "    axs[0].imshow(im_tensor.permute(1,2,0))\n",
    "    axs[0].add_patch(rect)\n",
    "    axs[0].set_title('camera view', fontsize=30)\n",
    "    # plt.show()\n",
    "    \n",
    "    frame = preprocess(im_tensor, x0, y0)\n",
    "    \n",
    "    frame_plt = frame * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "    axs[1].imshow(frame_plt.permute(1,2,0))\n",
    "    axs[1].set_title('target view', fontsize=20)\n",
    "    \n",
    "    \n",
    "    img_barplt = analyze_and_drawbar(frame)\n",
    "    axs[2].imshow(img_barplt)\n",
    "    \n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='jpeg')\n",
    "    buf.seek(0)\n",
    "    full_screen_img = Image.open(buf)\n",
    "    plt.close()\n",
    "    \n",
    "    full_screen_img = (to_tensor(full_screen_img)).permute(1,2,0).numpy()\n",
    "    full_screen_img = (full_screen_img*255).astype(np.uint8)\n",
    "    \n",
    "    cv2.imshow(windowname,cv2.cvtColor(full_screen_img, cv2.COLOR_RGB2BGR))\n",
    "    # cv2.imshow(windowname, im)\n",
    "#     #cv2.imshow(inner,viz)\n",
    "    \n",
    "    key = cv2.waitKey(20)\n",
    "#     if key & 0xFF == ord('1'):\n",
    "#         remap_std=0.1\n",
    "#     if key & 0xFF == ord('2'):\n",
    "#         remap_std=0.2\n",
    "    # if key & 0xFF == ord('3'):\n",
    "#         remap_std=0.3\n",
    "#     if key & 0xFF == ord('4'):\n",
    "#         remap_std=0.4\n",
    "#     if key & 0xFF == ord('5'):\n",
    "#         remap_std=0.5\n",
    "#     if key & 0xFF == ord('c'):\n",
    "#         mappings,densemapping=mkmappings_color()\n",
    "#         mkviz=True\n",
    "#     if key & 0xFF == ord('g'):\n",
    "#         mappings,densemapping=mkmappings_gray()\n",
    "#         mkviz=True\n",
    "#     if key & 0xFF == ord('v'):\n",
    "#         mkviz=not mkviz\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.startWindowThread()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
