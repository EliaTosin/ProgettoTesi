{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopo del notebook: \n",
    "- ## testare la rete su una sequenza di immagini\n",
    "- ## produrre un video con i risultati ottenuti\n",
    "\n",
    "#### Costanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# percorso dove ho salvato il modello\n",
    "SAVE_PATH = 'trained/resnet50_out8_best.pth'\n",
    "\n",
    "# fattore di ridimensionamento dell'immagine (prima di essere centrata con dimensione 300)\n",
    "RESIZE_VALUE = 600\n",
    "\n",
    "# percorso dove ho salvate le immagini\n",
    "test_path2 = 'images/stress-test/'\n",
    "# dove trovo le classi da predire\n",
    "test_path = 'data/images_scraped/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Resize, ToPILImage, CenterCrop, Normalize, Compose\n",
    "from torchvision.transforms.functional import to_grayscale, to_tensor, rotate, hflip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "from PIL.features import pilinfo\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "import cv2\n",
    "from numpy import asarray\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D3dUDXh9pJX"
   },
   "source": [
    "### Funzioni per recuperare i dati\n",
    "\n",
    " - getSingleLabelList(percorso del dataset): ritorna una Series costituita da indice numerico a cui associa l'immagine (nome) ed una finta label (visto che qui non ho un test vero e proprio ma osservo le predizioni fatte)\n",
    " - getSingleImgPool(percorso del dataset): ritorna una Series costituita da indice numerico a cui associa il percorso assoluto dell'immagine, la finta label e la finta classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the single class usage, i have only images in the test_path2 and i put manually the label to each\n",
    "def getSingleLabelList(path):\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    for img in [ name for name in os.listdir(path) ]:\n",
    "        ret[index] = [img, 0]\n",
    "        index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pool of images from video (with a series that contains all the images, more deeply: index -> abs path, label (int), class (string))\n",
    "\n",
    "def getSingleImgPool(path):\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    for img in [ name for name in os.listdir(path) ]:\n",
    "        abs_path = path + '/' + img\n",
    "        ret[index] = [abs_path, 0, 'fake class']\n",
    "        index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhMcw_pl9pJZ",
    "tags": []
   },
   "source": [
    "## Creazione della struttura dataset (contenitore di immagini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTutNs0v9pJb",
    "tags": []
   },
   "source": [
    "### ResNet18\n",
    "Non utilizzo la Lenet visto che il video è registrato in RGB e la Resnet è stata allenata con augmentation apposite che simulino un video (luminosità e traslazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUp7Z8IH9pJb"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, path_labels, transform=None, target_transform=None, use_aug=True):\n",
    "        self.img_labels = getSingleLabelList(path_labels)\n",
    "        self.images = getSingleImgPool(path_labels)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.use_aug = use_aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try: \n",
    "            image = Image.open(self.images.loc[idx][0])\n",
    "            if Image.MIME[image.format] == 'image/png': #formato errato\n",
    "                    image = convertPNGImage(self.images.loc[idx][0], 'PNG')\n",
    "        except Exception:\n",
    "            print('Found error at {} in position {}'.format(self.images.loc[idx][0], idx))\n",
    "\n",
    "        image = ToTensor()(image)\n",
    "\n",
    "        if image.shape[0] != 3: #converto le immagini in bianco e nero e RGBA in RGB\n",
    "            image = ToPILImage()(image).convert('RGB')  \n",
    "        else: #immagine già RGB\n",
    "            image = ToPILImage()(image)\n",
    "\n",
    "        preprocess = Compose([\n",
    "            Resize(RESIZE_VALUE),\n",
    "            CenterCrop(300),\n",
    "            ToTensor(),\n",
    "        ])\n",
    "        image = preprocess(image)\n",
    "\n",
    "        #parte di data augmentation\n",
    "        if self.use_aug:\n",
    "            fr = random.choices([0,1],[0.5,0.5])[0] # cambio luminosita (50% probabilità di capitare)\n",
    "            if fr == 1:\n",
    "                num = 0.5 + random.random()\n",
    "                image = adjust_brightness(image, num)\n",
    "\n",
    "            fr = random.choices([0,1],[0.2,0.8])[0] # rotazione (80% probabilità di capitare)\n",
    "            if fr == 1: \n",
    "                angle = torch.randint(40, size=(1,)).item() - 20\n",
    "                image = rotate(image, angle)\n",
    "\n",
    "            fr = random.choices([0,1],[0.5,0.5])[0] # specchiamento asse y (50% probabilità di capitare)\n",
    "            if fr == 1: \n",
    "                image = hflip(image)\n",
    "\n",
    "            fr = random.choices([0,1],[0.5,0.5])[0] # traslazione (50% probabilità di capitare)\n",
    "            if fr == 1:\n",
    "                trX = torch.randint(200, size=(1,)).item() - 100\n",
    "                trY = torch.randint(200, size=(1,)).item() - 100\n",
    "                image = affine(image, angle=0, translate=(trX, trY), scale=1, shear=0)\n",
    "\n",
    "            fr = random.choices([0,1],[0.5,0.5])[0] # rumore gaussiano (50% probabilità di capitare)\n",
    "            if fr == 1:\n",
    "                gauss_noise = np.random.normal(0, 0.4, (image.shape[1], image.shape[2]))\n",
    "                image = image + gauss_noise\n",
    "\n",
    "        preprocess2 = Compose([ # secondo preprocess dell'immagine per evitare problemi con il cambio luminosità\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        image = preprocess2(image)\n",
    "\n",
    "        label = self.img_labels.loc[idx][1]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8HbY1Gw9pJc"
   },
   "source": [
    "### Creazione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "nd4q0jbl9pJc",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "cefec1a1-f904-4a12-aca6-e5a418ee8a49"
   },
   "outputs": [],
   "source": [
    "test_data = CustomImageDataset(path_labels=test_path2, transform=ToTensor(), target_transform=ToTensor(), use_aug=False)\n",
    "\n",
    "print (f'N° immagini nel test dataset: {test_data.__len__()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifica caricamento delle immagini\n",
    "only_dirs = [ name for name in os.listdir(test_path) if \n",
    "                 os.path.isdir(os.path.join(test_path, name)) ]\n",
    "diz = {}\n",
    "nocl=0 # numero di classi\n",
    "for d in only_dirs:\n",
    "    diz[nocl] = d\n",
    "    nocl+=1\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(test_data), size=(1,)).item() \n",
    "    img, label = test_data[sample_idx]\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuNxVR_K9pJe"
   },
   "source": [
    "## Creazione dataloader (richiede immagini al dataset, producendo i batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_data, batch_size=24, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader test\n",
    "images, labels = next(iter(test_dl)) #prendo un batch\n",
    "print(f\"Feature batch shape: {images.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")\n",
    "img = images[0] # prendo prima immagine dal batch\n",
    "img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "label = labels[0]\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False)\n",
    "loaded.fc = torch.nn.Linear(2048, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.load_state_dict(torch.load(SAVE_PATH))\n",
    "loaded.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predizioni di 24 immagini casuali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_dl)) #picking a batch\n",
    "\n",
    "n_imgs = len(images)\n",
    "\n",
    "preds = loaded(images)\n",
    "_, best_pred = torch.max(preds.data, 1)\n",
    "\n",
    "figure = plt.figure(figsize=(24, 24))\n",
    "cols, rows = 4, int(n_imgs/4)\n",
    "for i in range(1, cols * rows + 1):\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title('Predetto: {}'.format(diz[best_pred[i-1].item()]))\n",
    "    plt.axis(\"off\")\n",
    "    images[i-1] = images[i-1] * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "    plt.imshow(images[i-1].permute(1,2,0)) #use this if rbg\n",
    "plt.show()\n",
    "\n",
    "# axs[i].set_title('T: {}\\nP: {}'.format(diz[label[i].item()], diz[best_pred[i].item()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costruzione del video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLT_SIZE = (24, 6) # necessario per dare la stessa dimensione al plot disegnato e al writer che lo scriverà come video\n",
    "\n",
    "fig, axs = plt.subplots(figsize=PLT_SIZE, nrows=1, ncols=2)\n",
    "size = fig.get_size_inches()*fig.dpi # recupero dimensione in pixel\n",
    "plt.close(fig)\n",
    "\n",
    "# scelta codifica (qui mp4)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# scelta percorso (qui è costruita come '[nome video]_[nome modello]_RESIZE_VALUE')\n",
    "VIDEO_PATH = 'video/' + test_path2.split('/')[1] + '_' + SAVE_PATH.split('/')[1] + '_' + str(RESIZE_VALUE) + '.mp4'\n",
    "# creazione videowriter (costruttore del video)\n",
    "video = cv2.VideoWriter(VIDEO_PATH, fourcc, 30, (int(size[0]),int(size[1])), isColor=True)\n",
    "\n",
    "test_dl_single = DataLoader(test_data, batch_size=1, shuffle=False) #batch che contiene l'immagine che analizzo\n",
    "diz2 = copy.deepcopy(diz) # dizionario che conterrà le predizioni associate alla classe\n",
    "\n",
    "\n",
    "i = 0\n",
    "for batch in test_dl_single:\n",
    "    imgs, label = batch\n",
    "    out = loaded(imgs)\n",
    "    _, best_pred = torch.max(out.data, 1)\n",
    "    perc = torch.nn.functional.softmax(out, dim=1)[0] * 100 # recupero attivazioni e trasformo in percentuali\n",
    "    _, indices = torch.sort(out, descending=True) # prelevo le classi\n",
    "    for img in imgs:\n",
    "        # preprocess immagine per openCV\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "        img = img.permute(1,2,0)\n",
    "        img = img.numpy()\n",
    "        img = (img*255).astype(np.uint8)\n",
    "        \n",
    "        fig, axs = plt.subplots(figsize=PLT_SIZE, nrows=1, ncols=2, gridspec_kw={'width_ratios': [1,2]})\n",
    "        \n",
    "        # disegno video\n",
    "        axs[0].axis('off')\n",
    "        axs[0].imshow(img)\n",
    "        axs[0].set_title('input frames', fontsize=20, fontweight='bold')\n",
    "\n",
    "        #creazione grafico a barre orizzontali\n",
    "        plt.xlim(0, 100)\n",
    "        for idx in indices[0][:8]: # assegno ad ogni la classe la sua percentuale\n",
    "            diz2[idx.item()] = perc[idx].item()\n",
    "        \n",
    "        keys = list(diz.keys())\n",
    "        plt.barh(keys, diz2.values())\n",
    "        axs[1].xaxis.set_ticks(np.linspace(0,100,21))\n",
    "        axs[1].set_yticks(keys, labels=list(diz.values()))\n",
    "        axs[1].grid(axis='x')\n",
    "        axs[1].tick_params(axis='both', labelsize=20)\n",
    "        axs[1].set_xlabel('confidence', fontsize=20, fontweight='bold')\n",
    "        axs[1].set_ylabel('labels', fontsize=20, fontweight='bold')\n",
    "        axs[1].set_title('predictions', fontsize=20, fontweight='bold')\n",
    "        \n",
    "        # salvataggio della figura costruita (video e grafico) in un'immagine\n",
    "        buffer = io.BytesIO()\n",
    "        fig.savefig(buffer, format='jpeg')\n",
    "        buffer.seek(0)\n",
    "        frame = Image.open(buffer)\n",
    "        frame = asarray(frame)\n",
    "        \n",
    "        # scrittura su video\n",
    "        video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        if i % 20 == 0 and i != 0: # durante la scrittura mostro dei frame del video costruito\n",
    "            print(f\"image processed: {i}/{test_data.__len__()}\")\n",
    "            plt.show()\n",
    "        \n",
    "        i +=1\n",
    "        plt.close(fig)\n",
    "\n",
    "        \n",
    "# chiusura costruttore (salva il video)\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "print('Video salvato al percorso: {}'.format(VIDEO_PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
