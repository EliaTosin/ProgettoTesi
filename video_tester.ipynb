{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#where to load the dataset labels\n",
    "test_path = 'data/images_scraped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#where to load the net to use\n",
    "SAVE_PATH = 'trained/scheduler_resnet/new_res18_25_best.pth'\n",
    "\n",
    "using_res = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Resize, ToPILImage, CenterCrop, Normalize, Compose\n",
    "from torchvision.transforms.functional import to_grayscale, to_tensor, rotate, hflip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "from PIL.features import pilinfo\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_dirs = [ name for name in os.listdir(test_path) if \n",
    "                 os.path.isdir(os.path.join(test_path, name)) ]\n",
    "\n",
    "diz = {}\n",
    "nocl=0 #num of classes\n",
    "for d in only_dirs:\n",
    "    diz[nocl] = d\n",
    "    nocl+=1\n",
    "    \n",
    "print(diz.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where the images are located and their class\n",
    "test_path2 = 'images/hyundai-conv1/'\n",
    "SINGLE_CLASS = 'hyundai'\n",
    "\n",
    "LABEL_INDEX = list(diz.values()).index(SINGLE_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions to retrive the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a annotations_file.csv (index -> img (name), label (int))\n",
    "\n",
    "def getLabelList(path):\n",
    "    only_dirs = [ name for name in os.listdir(path) if \n",
    "                 os.path.isdir(os.path.join(path, name)) ]\n",
    "\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    \n",
    "    for d in only_dirs:\n",
    "        new_path = path + d\n",
    "        label = only_dirs.index(d)\n",
    "        # print(len(os.listdir(new_path)))\n",
    "        for img in [ name for name in os.listdir(new_path) ]:\n",
    "            ret[index] = [img, label]\n",
    "            index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the single class usage, i have only images in the test_path2 and i put manually the label to each\n",
    "def getSingleLabelList(path):\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    for img in [ name for name in os.listdir(path) ]:\n",
    "        ret[index] = [img, LABEL_INDEX]\n",
    "        index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pool of images (with a series that contains all the images, more deeply: index -> abs path, label (int), class (string))\n",
    "\n",
    "def getImgPool(path):\n",
    "    only_dirs = [ name for name in os.listdir(path) if \n",
    "                 os.path.isdir(os.path.join(path, name)) ]\n",
    "\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    \n",
    "    for d in only_dirs:\n",
    "        new_path = path + d\n",
    "        label = only_dirs.index(d)\n",
    "        # cnt = 0\n",
    "        for img in [ name for name in os.listdir(new_path) ]:\n",
    "            abs_path = new_path + '/' + img\n",
    "            ret[index] = [abs_path, label, d]\n",
    "            index += 1\n",
    "            # cnt += 1\n",
    "        # print(f\"Label: {d} - Number: {cnt}\")\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pool of images from video (with a series that contains all the images, more deeply: index -> abs path, label (int), class (string))\n",
    "\n",
    "def getSingleImgPool(path):\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    for img in [ name for name in os.listdir(path) ]:\n",
    "        abs_path = path + '/' + img\n",
    "        ret[index] = [abs_path, LABEL_INDEX, SINGLE_CLASS]\n",
    "        index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the custom dataset (structure that holds the data)\n",
    "\n",
    "#### old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    # wrong_images_path = []\n",
    "    # import traceback\n",
    "\n",
    "    class CustomImageDataset(Dataset):\n",
    "        def __init__(self, path_labels, transform=None, target_transform=None, use_aug=True, single_class=None):\n",
    "            if single_class is not None:\n",
    "                self.img_labels = getSingleLabelList(path_labels)\n",
    "                self.images = getSingleImgPool(path_labels)\n",
    "            else:\n",
    "                self.img_labels = getLabelList(path_labels)\n",
    "                self.images = getImgPool(path_labels)\n",
    "            self.transform = transform\n",
    "            self.target_transform = target_transform\n",
    "            self.use_aug = use_aug\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.img_labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            try: \n",
    "                image = read_image(self.images.loc[idx][0])\n",
    "            except Exception:\n",
    "                print('Found error at {} {}'.format(self.images.loc[idx][0], idx))\n",
    "            #     wrong_images_path.append(self.images.loc[img_name][0])\n",
    "                #return torch.zeros((1, 600, 600)), -1\n",
    "            # image = read_image(self.images.loc[img_name][0])\n",
    "            if image.shape[0] >= 3: #apply grayscale to colored img\n",
    "                image = to_tensor(to_grayscale(ToPILImage()(image), num_output_channels=1))\n",
    "            else: #we have a greyscaled image, move it into tensor \n",
    "                image = to_tensor(ToPILImage()(image))\n",
    "\n",
    "            image = Resize((300, 300))(image)\n",
    "            #data augmentation\n",
    "            if self.use_aug:\n",
    "                fr = random.choices([0,1],[0.2,0.8])[0]\n",
    "                if fr == 1: \n",
    "                    angle = torch.randint(40, size=(1,)).item() - 20\n",
    "                    #print (f'Rotate: {angle}')\n",
    "                    image = rotate(image, angle)\n",
    "\n",
    "                fr = random.choices([0,1],[0.5,0.5])[0]\n",
    "                if fr == 1: \n",
    "                    image = hflip(image)\n",
    "\n",
    "            #image = image.permute(1,2,0) #made to be shown on matplotlib\n",
    "            label = self.img_labels.loc[idx][1]\n",
    "            #if self.transform:\n",
    "            #    image = self.transform(image)\n",
    "            #if self.target_transform:\n",
    "            #    label = self.target_transform(label)\n",
    "\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new version (resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_res:\n",
    "    wrong_images_path = []\n",
    "\n",
    "    class CustomImageDataset(Dataset):\n",
    "        def __init__(self, path_labels, transform=None, target_transform=None, use_aug=True, single_class=None):\n",
    "            if single_class is not None:\n",
    "                self.img_labels = getSingleLabelList(path_labels)\n",
    "                self.images = getSingleImgPool(path_labels)\n",
    "            else:\n",
    "                self.img_labels = getLabelList(path_labels)\n",
    "                self.images = getImgPool(path_labels)\n",
    "            self.transform = transform\n",
    "            self.target_transform = target_transform\n",
    "            self.use_aug = use_aug\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.img_labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            try: \n",
    "                image = Image.open(self.images.loc[idx][0])\n",
    "                # exif_data = image._getexif()\n",
    "                if Image.MIME[image.format] == 'image/png': #wrong format, we want only jpg\n",
    "                        image = convertPNGImage(self.images.loc[idx][0], 'PNG')\n",
    "            # except UserWarning:\n",
    "            #     print('Found exif error at {} in position {}'.format(self.images.loc[idx][0], idx))\n",
    "            #     wrong_images_path.append('EXIF '+self.images.loc[idx][0])\n",
    "            except Exception:\n",
    "                print('Found exif error at {} in position {}'.format(self.images.loc[idx][0], idx))\n",
    "                # wrong_images_path.append(self.images.loc[idx][0])\n",
    "                \n",
    "            image = ToTensor()(image)\n",
    "            \n",
    "            if image.shape[0] != 3: #color grayscaled and convert RGBA\n",
    "                image = ToPILImage()(image).convert('RGB')\n",
    "                \n",
    "            else: #rgb, don't touch it \n",
    "                image = ToPILImage()(image)\n",
    "                \n",
    "            preprocess = Compose([\n",
    "                Resize(300),\n",
    "                CenterCrop(300),\n",
    "                ToTensor(),\n",
    "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "            image = preprocess(image)\n",
    "            \n",
    "            \n",
    "            #  COMMENT ME\n",
    "            # print(f\"idx: {idx} - path: {self.images.loc[idx][0]}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            #data augmentation\n",
    "            if self.use_aug:\n",
    "                fr = random.choices([0,1],[0.2,0.8])[0]\n",
    "                if fr == 1: \n",
    "                    angle = torch.randint(40, size=(1,)).item() - 20\n",
    "                    #print (f'Rotate: {angle}')\n",
    "                    image = rotate(image, angle)\n",
    "\n",
    "                fr = random.choices([0,1],[0.5,0.5])[0]\n",
    "                if fr == 1: \n",
    "                    image = hflip(image)\n",
    "\n",
    "            label = self.img_labels.loc[idx][1]\n",
    "\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the 2 dataset and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# train_data = CustomImageDataset(path_labels=train_path, transform=ToTensor(), num_of_channels=3)\n",
    "# test_data = CustomImageDataset(path_labels=test_path, transform=ToTensor(), num_of_channels=3)\n",
    "\n",
    "test_data = CustomImageDataset(path_labels=test_path2, transform=ToTensor(), \n",
    "                               target_transform=ToTensor(), use_aug=False, single_class=SINGLE_CLASS)\n",
    "\n",
    "print (f'test dataset: {test_data.__len__()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing dataset if images are loaded\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(test_data), size=(1,)).item() \n",
    "    img, label = test_data[sample_idx]\n",
    "    if using_res:\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "    # print (img.shape, img.dtype, label)\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(diz[label])\n",
    "    plt.axis(\"off\")\n",
    "    if not using_res:\n",
    "        plt.imshow(img.squeeze(), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img.permute(1,2,0)) #use this if rbg\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating dataloader (who iterate on data, create batches and shuffles it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_data, batch_size=24, shuffle=True)\n",
    "\n",
    "#dataloader test (ask a batch or a sample)\n",
    "images, labels = next(iter(test_dl)) #picking a batch\n",
    "print(f\"Feature batch shape: {images.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")\n",
    "img = images[0] #picking the first img and label of the batch\n",
    "\n",
    "if using_res:\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "label = labels[0]\n",
    "if not using_res:\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "else:\n",
    "    plt.imshow(img.permute(1,2,0)) #use this if rbg\n",
    "plt.show()\n",
    "print(f\"Label: {diz[label.item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU compute available: \", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            #conv1: 1 input image channel (image channel, 1 gray, 3 rgb), 6 output channels (depth [K]), 5x5 square convolution kernel, DEFAULT: stride = 1,1, padding = 0\n",
    "            self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)        \n",
    "            self.fc_layer1 = nn.Linear(16 * 72 * 72, 120)        \n",
    "            self.fc_layer2 = nn.Linear(120, 84)\n",
    "            self.fc_layer3 = nn.Linear(84, nocl) # nocl is the num of classes\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Max pooling over a (2, 2) window\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            #print ('conv1', x.shape)\n",
    "            # If the size is a square, you can specify with a single number\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "            #print ('flatten', x.shape)\n",
    "            x = F.relu(self.fc_layer1(x))\n",
    "            x = F.relu(self.fc_layer2(x))\n",
    "            x = self.fc_layer3(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the network on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    loaded = Net()\n",
    "else:\n",
    "    loaded = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.load_state_dict(torch.load(SAVE_PATH))\n",
    "loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_data, batch_size=24)\n",
    "images, labels = next(iter(test_dl)) #picking a batch\n",
    "\n",
    "n_imgs = len(images)\n",
    "\n",
    "preds = loaded(images)\n",
    "_, best_pred = torch.max(preds.data, 1)\n",
    "\n",
    "figure = plt.figure(figsize=(24, 24))\n",
    "cols, rows = 4, int(n_imgs/4)\n",
    "for i in range(1, cols * rows + 1):\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title('T: {}\\nP: {}'.format(diz[labels[i-1].item()], diz[best_pred[i-1].item()]))\n",
    "    plt.axis(\"off\")\n",
    "    if not using_res:\n",
    "        plt.imshow(images[i-1].squeeze(), cmap='gray')\n",
    "    else:\n",
    "        images[i-1] = images[i-1] * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "        plt.imshow(images[i-1].permute(1,2,0)) #use this if rbg\n",
    "plt.show()\n",
    "\n",
    "# axs[i].set_title('T: {}\\nP: {}'.format(diz[label[i].item()], diz[best_pred[i].item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in diz}\n",
    "total_pred = {classname: 0 for classname in diz}\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# again no gradients needed\n",
    "# with torch.no_grad():\n",
    "for data in test_dl:\n",
    "    images, labels = data\n",
    "    outputs = loaded(images)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    # collect the correct predictions for each class\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label == prediction:\n",
    "            correct_pred[label.item()] += 1\n",
    "        else:\n",
    "            correct_pred[prediction.item()] += 1 \n",
    "        total_pred[label.item()] += 1\n",
    "        y_true.append(label.cpu())\n",
    "        y_pred.append(prediction.cpu())\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    if total_pred[classname] == 0: #wrong class pred\n",
    "        accuracy = 100 * float(correct_count) / test_data.__len__()\n",
    "    else:\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Predictions for class: {diz[classname]} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
