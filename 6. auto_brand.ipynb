{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis:\n",
    "\n",
    "### Train set\n",
    "\n",
    "| Label name | | Number of images |\n",
    "| - | | - | \n",
    "| hyundai | | 302 | \n",
    "| lexus | | 301 | \n",
    "| mazda | | 317 | \n",
    "| mercedes | | 342 | \n",
    "| opel | | 301 | \n",
    "| skoda | | 314 | \n",
    "| toyota | | 306 | \n",
    "| volkswagen | | 330 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set\n",
    "| Label name | | Number of images |\n",
    "| - | | - | \n",
    "| hyundai | | 50 | \n",
    "| lexus | | 50 | \n",
    "| mazda | | 50 | \n",
    "| mercedes | | 50 | \n",
    "| opel | | 50 | \n",
    "| skoda | | 50 | \n",
    "| toyota | | 50 | \n",
    "| volkswagen | | 50 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Resize, ToPILImage\n",
    "from torchvision.transforms.functional import to_grayscale, to_tensor, rotate, hflip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions to retrive the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a annotations_file.csv (index -> img (name), label (int))\n",
    "\n",
    "def getLabelList(path):\n",
    "    only_dirs = [ name for name in os.listdir(path) if \n",
    "                 os.path.isdir(os.path.join(path, name)) ]\n",
    "\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    \n",
    "    for d in only_dirs:\n",
    "        new_path = path + d\n",
    "        label = only_dirs.index(d)\n",
    "        # print(len(os.listdir(new_path)))\n",
    "        for img in [ name for name in os.listdir(new_path) ]:\n",
    "            ret[index] = [img, label]\n",
    "            index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pool of images (with a series that contains all the images, more deeply: index -> abs path, label (int), class (string))\n",
    "\n",
    "def getImgPool(path):\n",
    "    only_dirs = [ name for name in os.listdir(path) if \n",
    "                 os.path.isdir(os.path.join(path, name)) ]\n",
    "\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    \n",
    "    for d in only_dirs:\n",
    "        new_path = path + d\n",
    "        label = only_dirs.index(d)\n",
    "        # cnt = 0\n",
    "        for img in [ name for name in os.listdir(new_path) ]:\n",
    "            abs_path = new_path + '/' + img\n",
    "            ret[index] = [abs_path, label, d]\n",
    "            index += 1\n",
    "            # cnt += 1\n",
    "        # print(f\"Label: {d} - Number: {cnt}\")\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the custom dataset (structure that holds the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_images_path = []\n",
    "import traceback\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, path_labels, transform=None, target_transform=None):\n",
    "        self.img_labels = getLabelList(path_labels)\n",
    "        self.images = getImgPool(path_labels)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try: \n",
    "            image = read_image(self.images.loc[idx][0])\n",
    "        except Exception:\n",
    "            print('Found error at {} {}'.format(self.images.loc[idx][0], idx))\n",
    "        #     wrong_images_path.append(self.images.loc[img_name][0])\n",
    "            #return torch.zeros((1, 600, 600)), -1\n",
    "        # image = read_image(self.images.loc[img_name][0])\n",
    "        if image.shape[0] >= 3: #apply grayscale to colored img\n",
    "            image = to_tensor(to_grayscale(ToPILImage()(image), num_output_channels=1))\n",
    "        else: #we have a greyscaled image, move it into tensor \n",
    "            image = to_tensor(ToPILImage()(image))\n",
    "            \n",
    "        image = Resize((300, 300))(image)\n",
    "        #data augmentation\n",
    "        fr = random.choices([0,1],[0.2,0.8])[0]\n",
    "        if fr == 1: \n",
    "            angle = torch.randint(40, size=(1,)).item() - 20\n",
    "            #print (f'Rotate: {angle}')\n",
    "            image = rotate(image, angle)\n",
    "            \n",
    "        fr = random.choices([0,1],[0.5,0.5])[0]\n",
    "        if fr == 1: \n",
    "            image = hflip(image)\n",
    "        \n",
    "        #image = image.permute(1,2,0) #made to be shown on matplotlib\n",
    "        label = self.img_labels.loc[idx][1]\n",
    "        #if self.transform:\n",
    "        #    image = self.transform(image)\n",
    "        #if self.target_transform:\n",
    "        #    label = self.target_transform(label)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the 2 dataset and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_path = 'data/car_brand_logos/Train/'\n",
    "test_path = 'data/car_brand_logos/Test/'\n",
    "\n",
    "SAVE_PATH = 'trained/auto_brand_hflip_3e2.pth'\n",
    "RUNS_PATH = 'runs/car_brands_hflip_3e2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# train_data = CustomImageDataset(path_labels=train_path, transform=ToTensor(), num_of_channels=3)\n",
    "# test_data = CustomImageDataset(path_labels=test_path, transform=ToTensor(), num_of_channels=3)\n",
    "\n",
    "train_data = CustomImageDataset(path_labels=train_path, transform=ToTensor(), target_transform=ToTensor())\n",
    "\n",
    "test_data = CustomImageDataset(path_labels=test_path, transform=ToTensor(), target_transform=ToTensor())\n",
    "\n",
    "print (f'train dataset: {train_data.__len__()}')\n",
    "print (f'test dataset: {test_data.__len__()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(train_data.__len__()):\n",
    "#     img, label = train_data[i]\n",
    "\n",
    "# for i in range(test_data.__len__()):\n",
    "#     img, label = test_data[i]\n",
    "    \n",
    "    \n",
    "# wrong_images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing dataset if images are loaded\n",
    "\n",
    "only_dirs = [ name for name in os.listdir(train_path) if \n",
    "                 os.path.isdir(os.path.join(train_path, name)) ]\n",
    "\n",
    "diz = {}\n",
    "nocl=0 #num of classes\n",
    "for d in only_dirs:\n",
    "    diz[nocl] = d\n",
    "    nocl+=1\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item() \n",
    "    img, label = train_data[sample_idx]\n",
    "    # print (img.shape, img.dtype, label)\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(diz[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    # plt.imshow(img.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# img, label = train_data[300]\n",
    "\n",
    "# print(img.shape)\n",
    "\n",
    "# plt.imshow(img.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating dataloader (who iterate on data, create batches and shuffles it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_data, batch_size=8, shuffle=True, pin_memory=True)\n",
    "test_dl = DataLoader(test_data, batch_size=8, shuffle=True)\n",
    "\n",
    "#dataloader test (ask a batch or a sample)\n",
    "images, labels = next(iter(train_dl)) #picking a batch\n",
    "print(f\"Feature batch shape: {images.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")\n",
    "img = images[0].permute(1,2,0) #picking the first img and label of the batch\n",
    "label = labels[0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "print(f\"Label: {diz[label.item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.rename('./data/car_brand_logos/Train/mercedes/r6.JPG', './data/car_brand_logos/Train/mercedes/r6.jpg')\n",
    "# image = read_image('./data/car_brand_logos/Train/volkswagen/vosvos-volkswagen-logo-patches-arma-pec-kot-yamasi__1548797389090801.jpg')\n",
    "# image = image.permute(1,2,0)\n",
    "# plt.imshow(image, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU compute available: \", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #conv1: 1 input image channel (image channel, 1 gray, 3 rgb), 6 output channels (depth [K]), 5x5 square convolution kernel, DEFAULT: stride = 1,1, padding = 0\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)        \n",
    "        self.fc_layer1 = nn.Linear(16 * 72 * 72, 120)        \n",
    "        self.fc_layer2 = nn.Linear(120, 84)\n",
    "        self.fc_layer3 = nn.Linear(84, nocl) # nocl is the num of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print ('conv1', x.shape)\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        #print ('flatten', x.shape)\n",
    "        x = F.relu(self.fc_layer1(x))\n",
    "        x = F.relu(self.fc_layer2(x))\n",
    "        x = self.fc_layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# use gradient descent\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = Net()\n",
    "best_net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard setup\n",
    "\n",
    "start tensorboard: `tensorboard --logdir=Users\\eliad\\Tesi\\ProgettoTesi\\runs\\car_brands_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = SummaryWriter(RUNS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get some random training images\n",
    "# dataiter = iter(train_dl)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# #visualizing and adding images into tb\n",
    "# for idx in range(4):    \n",
    "#     img = images[idx]\n",
    "#     plt.imshow(img.squeeze(), cmap='gray')\n",
    "#     plt.show()\n",
    "#     print (img.shape, img.dtype)\n",
    "#     writer.add_image(f\"car_brands_images_{idx+1}\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the graph of the network into Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_graph(net, images.to(device))\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the projector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_dl = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "# images, labels = next(iter(tmp_dl))\n",
    "\n",
    "# # get the class labels for each image\n",
    "# class_labels = [diz[lab.item()] for lab in labels]\n",
    "\n",
    "\n",
    "# images = Resize((28, 28))(images)\n",
    "\n",
    "# features = images.view(-1, 28 * 28)\n",
    "# writer.add_embedding(features,\n",
    "#                     metadata=class_labels,\n",
    "#                     label_img=images)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createConfusionMatrix(loader, netw):\n",
    "    y_pred = [] # save predction\n",
    "    y_true = [] # save ground truth\n",
    "\n",
    "    # iterate over data\n",
    "    for inputs, labels in loader:\n",
    "        output = netw(inputs.to(device))  # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output)  # save prediction\n",
    "\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels)  # save ground truth\n",
    "\n",
    "    # constant for classes\n",
    "    classes = diz.values()\n",
    "\n",
    "    # Build confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) * 10, index=[i for i in classes],\n",
    "                         columns=[i for i in classes])\n",
    "    plt.figure(figsize=(7, 7), dpi=125)\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='jpeg')\n",
    "    buf.seek(0)\n",
    "    im = Image.open(buf)\n",
    "    im = ToTensor()(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(net.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_loss = 10000\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        # get the inputs; data is a list of [inputsdeviceels]\n",
    "        inputs, labels = data\n",
    "        # inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        #print (inputs.shape)\n",
    "        #inputs = inputs.permute(0, 3, 1, 2) # to get a shape of [64, 1, 600, 600]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #print (inputs.device, label.device)\n",
    "\n",
    "        # inputs = inputs.view(64, -1) #1° param specifico io, altri calcola lui (-1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print (outputs.device)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        skip = 50\n",
    "        if i > 0  and i % 50 == 0:    # print every 360 images (8 images per batch, 45 loops)\n",
    "            print(f'[{epoch + 1}, {i}/{len(train_dl)}] loss: {(running_loss/skip):.3f}')\n",
    "            # ...log the running loss\n",
    "            # writer.add_scalar('training loss',\n",
    "            #            running_loss / skip,\n",
    "            #            epoch * len(train_dl) + i)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    #end of an epoch, calculate loss on test set (since it's small and there's no need to split)\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        test_batch = 0\n",
    "        net.eval()\n",
    "        for _, data in enumerate(test_dl):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #inputs = inputs.permute(0, 3, 1, 2)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_batch += 1\n",
    "        actual_test_loss = test_loss/test_batch\n",
    "        print(f\"[{epoch + 1}] test loss: {(actual_test_loss):.3f}\")\n",
    "        if actual_test_loss < best_test_loss:\n",
    "            best_test_loss = actual_test_loss\n",
    "            best_net.train()\n",
    "            best_net = net\n",
    "            best_net.eval()\n",
    "        # writer.add_scalar('test loss',\n",
    "        #                test_loss/test_batch,\n",
    "        #                epoch+1)\n",
    "        # confusion matrix (added from extra step)        \n",
    "        # writer.add_image(\"confusion_matrix2\", createConfusionMatrix(test_dl, net), global_step=epoch)\n",
    "        # writer.close()\n",
    "        \n",
    "\n",
    "print('Finished Training')\n",
    "print(f\"best test loss: {best_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the trained model\n",
    "torch.save(net.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the network on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = Net()\n",
    "# loaded.load_state_dict(torch.load(\"trained/auto_brand_no_flip_16e.pth\"))\n",
    "loaded.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.to(device)\n",
    "loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_dl)) #picking a batch\n",
    "\n",
    "n_imgs = len(images)\n",
    "img = images.to(device)\n",
    "label = labels.to(device)\n",
    "\n",
    "preds = net(img)\n",
    "_, best_pred = torch.max(preds.data, 1)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(25,4), nrows=1, ncols=n_imgs)\n",
    "\n",
    "for i in range(n_imgs):\n",
    "    axs[i].imshow(img[i].permute(1,2,0).cpu(), cmap='gray')\n",
    "    axs[i].set_title('T: {}\\nP: {}'.format(diz[label[i].item()], diz[best_pred[i].item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# # 2. gets the preds in a test_size Tensor\n",
    "# class_probs = []\n",
    "# class_label = []\n",
    "# with torch.no_grad():\n",
    "#     for data in test_dl:\n",
    "#         images, labels = data\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         output = net(images)\n",
    "#         class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "#         class_probs.append(class_probs_batch)\n",
    "#         class_label.append(labels)\n",
    "\n",
    "# test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "# test_label = torch.cat(class_label)\n",
    "\n",
    "# # helper function\n",
    "# def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "#     '''\n",
    "#     Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "#     precision-recall curve\n",
    "#     '''\n",
    "#     tensorboard_truth = test_label == class_index\n",
    "#     tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "#     writer.add_pr_curve(diz[class_index],\n",
    "#                         tensorboard_truth,\n",
    "#                         tensorboard_probs,\n",
    "#                         global_step=global_step)\n",
    "#     writer.close()\n",
    "\n",
    "# # plot all the pr curves\n",
    "# for i in range(len(diz.values())):\n",
    "#    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in diz}\n",
    "total_pred = {classname: 0 for classname in diz}\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_dl:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[label.item()] += 1\n",
    "            total_pred[label.item()] += 1\n",
    "            y_true.append(label.cpu())\n",
    "            y_pred.append(prediction.cpu())\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {diz[classname]} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stampa report classificazioni\n",
    "print(classification_report(y_true, y_pred, target_names=diz.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20,12), nrows=1, ncols=2)\n",
    "axs[0].imshow(createConfusionMatrix(test_dl, net).permute(1,2,0))\n",
    "axs[0].set_title('Trained Net')\n",
    "axs[1].imshow(createConfusionMatrix(test_dl, net).permute(1,2,0))\n",
    "axs[1].set_title('Loaded Net')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
