{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopo del notebook: allenare la rete neurale su Car Brand Logos\n",
    "\n",
    "#### Costanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "uI6r0zF69pJJ",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# dimensione del batch\n",
    "BATCH_SIZE = 8\n",
    "# n° di epoche del training\n",
    "NUM_OF_EPOCHS = 25\n",
    "\n",
    "# definisce se usare augmentation nel training set\n",
    "USE_AUG = True\n",
    "# definisce se loggare i dati in Tensorboard\n",
    "log_to_tb = True\n",
    "# definisce se usare la ResNet18 (true) o LeNet5 (false)\n",
    "using_res = True\n",
    "# nome del file .pth che conterrà la rete allenata e l'eventuale cartella di tensorboard\n",
    "NET_NAME = 'resnet18_aug'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rcGlq6D9pJP"
   },
   "source": [
    "#### Percorsi di salvataggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgPjK2D_9pJR"
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = 'trained/' + NET_NAME + '.pth'\n",
    "SAVE_PATH2 = 'trained/' + NET_NAME + '_best.pth'\n",
    "RUNS_PATH = 'runs/' + NET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percorso dove trovare train e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "a23tioZT9pJS",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_path = 'data/car_brand_logos/Train/'\n",
    "test_path = 'data/car_brand_logos/Test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKQo8xFY9pJT"
   },
   "source": [
    "## Data analysis: Car Brand Logos\n",
    "\n",
    "### Train set\n",
    "\n",
    "| Label name | | Number of images |\n",
    "| - | | - | \n",
    "| hyundai | | 302 | \n",
    "| lexus | | 301 | \n",
    "| mazda | | 316 | \n",
    "| mercedes | | 342 | \n",
    "| opel | | 301 | \n",
    "| skoda | | 314 | \n",
    "| toyota | | 306 | \n",
    "| volkswagen | | 330 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7reo_awE9pJU",
    "tags": []
   },
   "source": [
    "### Test set\n",
    "| Label name | | Number of images |\n",
    "| - | | - | \n",
    "| hyundai | | 50 | \n",
    "| lexus | | 50 | \n",
    "| mazda | | 50 | \n",
    "| mercedes | | 50 | \n",
    "| opel | | 50 | \n",
    "| skoda | | 50 | \n",
    "| toyota | | 50 | \n",
    "| volkswagen | | 50 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx1FCJEL9pJV"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "kWtoMkAV9pJW",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Resize, ToPILImage, CenterCrop, Normalize, Compose\n",
    "from torchvision.transforms.functional import to_grayscale, to_tensor, rotate, hflip, affine, adjust_brightness\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "from PIL.features import pilinfo\n",
    "\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D3dUDXh9pJX"
   },
   "source": [
    "### Funzioni per recuperare i dati\n",
    "\n",
    " - getLabelList(percorso del dataset): ritorna una Series costituita da indice numerico a cui associa l'immagine (nome) e la sua label (valore numerico)\n",
    " - getImgPool(percorso del dataset): ritorna una Series costituita da indice numerico a cui associa il percorso assoluto dell'immagine, la label (valore numerico) e la corrisponde classe (stringa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qeg4aPqp9pJX"
   },
   "outputs": [],
   "source": [
    "def getLabelList(path):\n",
    "    only_dirs = [ name for name in os.listdir(path) if \n",
    "                 os.path.isdir(os.path.join(path, name)) ]\n",
    "\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    \n",
    "    for d in only_dirs:\n",
    "        new_path = path + d\n",
    "        label = only_dirs.index(d)\n",
    "        for img in [ name for name in os.listdir(new_path) ]:\n",
    "            ret[index] = [img, label]\n",
    "            index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TpIgryw9pJY"
   },
   "outputs": [],
   "source": [
    "def getImgPool(path):\n",
    "    only_dirs = [ name for name in os.listdir(path) if \n",
    "                 os.path.isdir(os.path.join(path, name)) ]\n",
    "\n",
    "    ret = {}\n",
    "    index = 0\n",
    "    \n",
    "    for d in only_dirs:\n",
    "        new_path = path + d\n",
    "        label = only_dirs.index(d)\n",
    "        for img in [ name for name in os.listdir(new_path) ]:\n",
    "            abs_path = new_path + '/' + img\n",
    "            ret[index] = [abs_path, label, d]\n",
    "            index += 1\n",
    "    \n",
    "    return pd.Series(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funzione per convertire le immagini di formato diverso\n",
    "data un'immagine diversa dalle JPG (WEBP o PNG in questo dataset) le codifica in jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qo6Tzgqw9pJZ"
   },
   "outputs": [],
   "source": [
    "# convert a given format image hidden in JPG format, converting it to a JPG and overwriting the original with its format (WEBP or PNG)\n",
    "\n",
    "def convertPNGImage(path, start_format):\n",
    "    img = Image.open(path, formats=[start_format])\n",
    "    new_path = path[:-3] + 'jpg'\n",
    "    img.convert('RGB').save(new_path)\n",
    "    image = Image.open(new_path, formats=['JPEG'])\n",
    "    return image    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhMcw_pl9pJZ",
    "tags": []
   },
   "source": [
    "## Creazione della struttura dataset (contenitore di immagini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANyx-fNV9pJa",
    "tags": []
   },
   "source": [
    "### LeNet5\n",
    "Caratteristiche: immagini in bianco e nero, augmentation usate: rotazione e specchiamento asse y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kogV1IN89pJa"
   },
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    class CustomImageDataset(Dataset):\n",
    "        def __init__(self, path_labels, transform=None, target_transform=None, use_aug=True):\n",
    "            self.img_labels = getLabelList(path_labels)\n",
    "            self.images = getImgPool(path_labels)\n",
    "            self.transform = transform\n",
    "            self.target_transform = target_transform\n",
    "            self.use_aug = use_aug\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.img_labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            try: \n",
    "                image = Image.open(self.images.loc[idx][0])\n",
    "                if Image.MIME[image.format] == 'image/webp': #formato errato\n",
    "                        image = convertPNGImage(self.images.loc[idx][0], 'WEBP')\n",
    "            except Exception:\n",
    "                print('Found error at {} in position {}'.format(self.images.loc[idx][0], idx))\n",
    "            image = ToTensor()(image)\n",
    "            \n",
    "            if image.shape[0] >= 3: #trasformo l'immagine in bianco e nero\n",
    "                image = to_tensor(to_grayscale(ToPILImage()(image), num_output_channels=1))\n",
    "            else: #già in bianco e nero, converto al Tensor \n",
    "                image = to_tensor(ToPILImage()(image))\n",
    "\n",
    "            image = Resize((300, 300))(image)\n",
    "            \n",
    "            #parte di data augmentation\n",
    "            if self.use_aug:\n",
    "                fr = random.choices([0,1],[0.2,0.8])[0] # rotazione (80% probabilità di capitare)\n",
    "                if fr == 1: \n",
    "                    angle = torch.randint(40, size=(1,)).item() - 20 \n",
    "                    image = rotate(image, angle)\n",
    "\n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # specchiamento asse y (80% probabilità di capitare)\n",
    "                if fr == 1: \n",
    "                    image = hflip(image)\n",
    "            label = self.img_labels.loc[idx][1]\n",
    "\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTutNs0v9pJb",
    "tags": []
   },
   "source": [
    "### ResNet18\n",
    "Caratteristiche: immagini a colori, augmentation usate: cambio luminosità, rotazione, \n",
    "specchiamento asse y, traslazione su entrambi gli assi tra 100 e -100px, rumore gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUp7Z8IH9pJb"
   },
   "outputs": [],
   "source": [
    "if using_res:\n",
    "    class CustomImageDataset(Dataset):\n",
    "        def __init__(self, path_labels, transform=None, target_transform=None, use_aug=True):\n",
    "            self.img_labels = getLabelList(path_labels)\n",
    "            self.images = getImgPool(path_labels)\n",
    "            self.transform = transform\n",
    "            self.target_transform = target_transform\n",
    "            self.use_aug = use_aug\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.img_labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            try: \n",
    "                image = Image.open(self.images.loc[idx][0])\n",
    "                if Image.MIME[image.format] == 'image/png': #formato errato\n",
    "                        image = convertPNGImage(self.images.loc[idx][0], 'PNG')\n",
    "            except Exception:\n",
    "                print('Found error at {} in position {}'.format(self.images.loc[idx][0], idx))\n",
    "                \n",
    "            image = ToTensor()(image)\n",
    "            \n",
    "            if image.shape[0] != 3: #converto le immagini in bianco e nero e RGBA in RGB\n",
    "                image = ToPILImage()(image).convert('RGB')  \n",
    "            else: #immagine già RGB\n",
    "                image = ToPILImage()(image)\n",
    "                \n",
    "            preprocess = Compose([\n",
    "                Resize(300),\n",
    "                CenterCrop(300),\n",
    "                ToTensor(),\n",
    "            ])\n",
    "            image = preprocess(image)\n",
    "            \n",
    "            #parte di data augmentation\n",
    "            if self.use_aug:\n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # cambio luminosita (50% probabilità di capitare)\n",
    "                if fr == 1:\n",
    "                    num = 0.5 + random.random()\n",
    "                    image = adjust_brightness(image, num)\n",
    "                \n",
    "                fr = random.choices([0,1],[0.2,0.8])[0] # rotazione (80% probabilità di capitare)\n",
    "                if fr == 1: \n",
    "                    angle = torch.randint(40, size=(1,)).item() - 20\n",
    "                    image = rotate(image, angle)\n",
    "\n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # specchiamento asse y (50% probabilità di capitare)\n",
    "                if fr == 1: \n",
    "                    image = hflip(image)\n",
    "                    \n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # traslazione (50% probabilità di capitare)\n",
    "                if fr == 1:\n",
    "                    trX = torch.randint(200, size=(1,)).item() - 100\n",
    "                    trY = torch.randint(200, size=(1,)).item() - 100\n",
    "                    image = affine(image, angle=0, translate=(trX, trY), scale=1, shear=0)\n",
    "                    \n",
    "                fr = random.choices([0,1],[0.5,0.5])[0] # rumore gaussiano (50% probabilità di capitare)\n",
    "                if fr == 1:\n",
    "                    gauss_noise = np.random.normal(0, 0.4, (image.shape[1], image.shape[2]))\n",
    "                    image = image + gauss_noise\n",
    "            \n",
    "            preprocess2 = Compose([ # secondo preprocess dell'immagine per evitare problemi con il cambio luminosità\n",
    "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            image = preprocess2(image)\n",
    "            \n",
    "            label = self.img_labels.loc[idx][1]\n",
    "\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8HbY1Gw9pJc"
   },
   "source": [
    "### Creazione dei 2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "nd4q0jbl9pJc",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "cefec1a1-f904-4a12-aca6-e5a418ee8a49"
   },
   "outputs": [],
   "source": [
    "train_data = CustomImageDataset(path_labels=train_path, transform=ToTensor(), target_transform=ToTensor(), use_aug=USE_AUG)\n",
    "test_data = CustomImageDataset(path_labels=test_path, transform=ToTensor(), target_transform=ToTensor(), use_aug=False)\n",
    "\n",
    "print (f'N° immagini nel train dataset: {train_data.__len__()}')\n",
    "print (f'N° immagini nel test dataset: {test_data.__len__()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "upqv1Vnx9pJd",
    "outputId": "2cf942e9-6df7-4b04-976e-63c378930f41"
   },
   "outputs": [],
   "source": [
    "#verifica caricamento delle immagini\n",
    "only_dirs = [ name for name in os.listdir(train_path) if \n",
    "                 os.path.isdir(os.path.join(train_path, name)) ]\n",
    "\n",
    "diz = {}\n",
    "nocl=0 # numero di classi\n",
    "for d in only_dirs:\n",
    "    diz[nocl] = d\n",
    "    nocl+=1\n",
    "\n",
    "figure = plt.figure(figsize=(12, 12))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item() \n",
    "    img, label = train_data[sample_idx]\n",
    "    if using_res: # rimuovo effetti normalizzazione (cattiva visualizzazione delle immagini)\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "    img = torch.clamp(img, 0, 1) # rimuovo effetti rumore gaussiano\n",
    "    \n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(diz[label])\n",
    "    plt.axis(\"off\")\n",
    "    if not using_res:\n",
    "        plt.imshow(img.squeeze(), cmap='gray') # visualizzazione lenet\n",
    "    else:\n",
    "        plt.imshow(img.permute(1,2,0)) # visualizzazione resnet\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuNxVR_K9pJe"
   },
   "source": [
    "## Creazione dataloader (richiede immagini al dataset, producendo i batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "0Dn-jlHc9pJf",
    "outputId": "90962960-d983-4657-a7dc-1029fecb8f5c"
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "test_dl = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "0Dn-jlHc9pJf",
    "outputId": "90962960-d983-4657-a7dc-1029fecb8f5c"
   },
   "outputs": [],
   "source": [
    "#dataloader test\n",
    "images, labels = next(iter(train_dl)) #prendo un batch\n",
    "print(f\"Feature batch shape: {images.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")\n",
    "# prendo prima immagine e label dal batch\n",
    "img = images[0]\n",
    "label = labels[0]\n",
    "if not using_res:\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "else:\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "plt.show()\n",
    "print(f\"Classe: {diz[label.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esempio augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_dl)) #prendo un batch dal test siccome non uso augmentation lì\n",
    "image = images[0]\n",
    "N_ROWS = 1\n",
    "if using_res:\n",
    "    N_ROWS = 2\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16,8), nrows=N_ROWS, ncols=3)\n",
    "if using_res:\n",
    "    image = image * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "\n",
    "    \n",
    "img=image\n",
    "axs[0][0].imshow(img.permute(1,2,0))\n",
    "axs[0][0].set_title('immagine originale')\n",
    "axs[0][0].axis('off')\n",
    "\n",
    "#applico rotazione\n",
    "angle = torch.randint(40, size=(1,)).item() - 20\n",
    "img = rotate(img, angle)\n",
    "axs[0][1].imshow(img.permute(1,2,0))\n",
    "axs[0][1].set_title('rotation (of {} degrees)'.format(angle))\n",
    "axs[0][1].axis('off')\n",
    "\n",
    "#applico specchiamento\n",
    "img = image\n",
    "img = hflip(img)\n",
    "axs[0][2].imshow(img.permute(1,2,0))\n",
    "axs[0][2].set_title('horizontal flip')\n",
    "axs[0][2].axis('off')\n",
    "if using_res:\n",
    "    #applico rumore\n",
    "    img = image\n",
    "    gauss_noise = np.random.normal(0, 0.4, (img.shape[1], img.shape[2]))\n",
    "    img = img + gauss_noise\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    axs[1][0].imshow(img.permute(1,2,0))\n",
    "    axs[1][0].set_title('gaussian noise')\n",
    "    axs[1][0].axis('off')\n",
    "\n",
    "    # cambio luminosità (1 valore base, vado ad aumentare/diminuire a caso con un limite di 0,5)\n",
    "    img = image\n",
    "    num = 0.5 + random.random()\n",
    "    img = adjust_brightness(img, num)\n",
    "    axs[1][1].imshow(img.permute(1,2,0))\n",
    "    axs[1][1].set_title(f\"change in brightness (of {int(num*100) - 100}%)\")\n",
    "    axs[1][1].axis('off')\n",
    "\n",
    "    # applico traslazione (tra -100, 100px su entrambi gli assi)\n",
    "    img = image\n",
    "    trX = torch.randint(200, size=(1,)).item() - 100\n",
    "    trY = torch.randint(200, size=(1,)).item() - 100\n",
    "    img = affine(img, angle=0, translate=(trX, trY), scale=1, shear=0)\n",
    "    axs[1][2].imshow(img.permute(1,2,0))\n",
    "    axs[1][2].set_title(f\"translation of ({trX},{-trY})\")\n",
    "    axs[1][2].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP2Ccger9pJf"
   },
   "source": [
    "## Definizione architettura della rete neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXf0Y8sG9pJg",
    "outputId": "10005594-263e-4f32-df3d-f672c241b77b"
   },
   "outputs": [],
   "source": [
    "print(\"GPU compute available: \", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3zA5UCO9pJg",
    "outputId": "326f8018-c970-45f1-de3c-5c5d9a443ad8"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANyx-fNV9pJa",
    "tags": []
   },
   "source": [
    "### LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loury7rK9pJg"
   },
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 6, 5)  # 1 indica il numero di canali dell'immagine (1 - bianco e nero)\n",
    "                                             # 6 indica i canali di uscita\n",
    "                                             # 5 indica la dimensione del filtro\n",
    "                                             # DEFAULT: passo = 1, padding = 0\n",
    "            self.pool = nn.MaxPool2d(2, 2) # finestra di pooling grande 2x2 (quindi dimezza altezza e larghezza dell'immagine)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)        \n",
    "            self.fc_layer1 = nn.Linear(16 * 72 * 72, 120)        \n",
    "            self.fc_layer2 = nn.Linear(120, 84)\n",
    "            self.fc_layer3 = nn.Linear(84, nocl) # nocl indica il numero di classi (8 qui)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc_layer1(x))\n",
    "            x = F.relu(self.fc_layer2(x))\n",
    "            x = self.fc_layer3(x)\n",
    "            return x\n",
    "        \n",
    "    net = Net()\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANyx-fNV9pJa",
    "tags": []
   },
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChLkArLA9pJg",
    "outputId": "0433ccf3-3ed7-40d5-8861-e651e89cf235"
   },
   "outputs": [],
   "source": [
    "if using_res:\n",
    "    net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0E0H1gP9pJh",
    "outputId": "f760e735-0748-416f-c3fc-a813d7aab20e"
   },
   "outputs": [],
   "source": [
    "#test struttura rete\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # verifico che il primo layer convolutivo sia stato costruito/caricato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function e gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f985SwG_9pJh"
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# uso stochastic gradient descent\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5) # scheduler ogni 5 epoche moltiplica il learning rate di 0.5 (dimezza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UysB8ZYG9pJh"
   },
   "source": [
    "## Configurazione Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5WXlhFo9pJh"
   },
   "outputs": [],
   "source": [
    "if log_to_tb:\n",
    "    writer = SummaryWriter(RUNS_PATH) # creo il logger dei dati\n",
    "\n",
    "    # aggiunta di immagini casuali al tensorboard\n",
    "    dataiter = iter(train_dl)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    for idx in range(4):    \n",
    "        img = images[idx]\n",
    "        if using_res:\n",
    "            img = img * torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        writer.add_image(f\"car_brands_images_{idx+1}\", img)\n",
    "\n",
    "    # aggiunta dello schema della rete \n",
    "    images = images.to(torch.float32)\n",
    "    writer.add_graph(net, images.to(device))\n",
    "\n",
    "    # aggiunta del projector \n",
    "    tmp_dl = DataLoader(train_data, batch_size=100, shuffle=True) #prendo 100 immagini\n",
    "    images, labels = next(iter(tmp_dl))\n",
    "    class_labels = [diz[lab.item()] for lab in labels]\n",
    "    \n",
    "    images = Resize((28, 28))(images) \n",
    "    # adattamento della shape del tensor a [100, dimensione immagine]\n",
    "    if using_res:\n",
    "        features = images.view(100, 3 * 28 * 28) \n",
    "    else:\n",
    "        features = images.view(-1, 28 * 28)\n",
    "    writer.add_embedding(features,\n",
    "                        metadata=class_labels,\n",
    "                        label_img=images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7Q8Znbb9pJi"
   },
   "source": [
    "## Addestramento della rete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rwx2rv1R9pJi",
    "outputId": "3051688e-86a6-4e17-a1fb-10400a284adf"
   },
   "outputs": [],
   "source": [
    "print(next(net.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKafXL7H9pJj",
    "outputId": "0758c421-0368-4a00-fa18-51996c841a5a"
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "for epoch in range(NUM_OF_EPOCHS):  # ciclo sul dataset\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        # prelevo immagini e label dal dataloader, poi le adatto\n",
    "        inputs, labels = data\n",
    "        batch_len = len(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs) # processo immagini, ottenendo predizioni\n",
    "        loss = criterion(outputs, labels) # calcolo loss\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        skip = 50\n",
    "        if i > 0  and i % skip == 0:    # stampa training loss ogni 50 * dimensione batch (50*8 qui)\n",
    "            print(f'[{epoch + 1}, {i}/{len(train_dl)}] loss: {(running_loss/skip):.3f}')\n",
    "            # salvataggio della train loss in tensorboard\n",
    "            if log_to_tb:\n",
    "                writer.add_scalar('training loss',\n",
    "                               running_loss / skip,\n",
    "                               (epoch * len(train_data)) + (i * batch_len))\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "\n",
    "    # fine di un'epoca, calcolo test loss e accuratezza (siccome qui il test dataset è piccolo)\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        test_total = 0\n",
    "        for _, data in enumerate(test_dl):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0) \n",
    "            test_acc += (predicted == labels).sum().item() \n",
    "            \n",
    "        actual_test_loss = test_loss/len(test_dl)\n",
    "        accuracy = (100 * test_acc / test_total)\n",
    "        \n",
    "        print(f\"[{epoch + 1}] test loss: {(actual_test_loss):.3f} , test acc: {accuracy}\")\n",
    "        if log_to_tb: # salvataggio test loss e accuratezza in tensorboard\n",
    "            writer.add_scalar('test loss',\n",
    "                           actual_test_loss,\n",
    "                           epoch+1)\n",
    "            writer.add_scalar('accuracy',\n",
    "                           accuracy,\n",
    "                           epoch+1)\n",
    "\n",
    "        # se l'accuratezza migliora, salvo il modello (migliore rispetto a prima)\n",
    "        if accuracy > best_accuracy:\n",
    "           best_accuracy = accuracy\n",
    "           torch.save(net.state_dict(), SAVE_PATH2)\n",
    "        \n",
    "\n",
    "print('Fine Addestramento')\n",
    "print(f\"Miglior acc: {best_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWZ94ny99pJj"
   },
   "outputs": [],
   "source": [
    "#salvo il modello prodotto alla 25a epoca\n",
    "torch.save(net.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test modello salvato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojt3lVlg9pJj",
    "outputId": "cf97e30c-9a5c-4263-dc69-e1e4935bdb30"
   },
   "outputs": [],
   "source": [
    "if not using_res:\n",
    "    loaded = Net()\n",
    "else:\n",
    "    loaded = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "    \n",
    "loaded.load_state_dict(torch.load(SAVE_PATH2))\n",
    "loaded.to(device)\n",
    "loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "X0iWZgu69pJj",
    "outputId": "b927d557-2a8d-4f75-8502-fd9695c1920a"
   },
   "outputs": [],
   "source": [
    "# salvataggio precision and recall curve (metrica per testare la bontà di un modello, basata sulla matrice di confusione della classe)\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(diz[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "\n",
    "if log_to_tb:\n",
    "    class_probs = []\n",
    "    class_label = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_dl:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = loaded(images)\n",
    "            class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "            class_probs.append(class_probs_batch)\n",
    "            class_label.append(labels)\n",
    "\n",
    "    test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "    test_label = torch.cat(class_label)\n",
    "\n",
    "    # plot all the pr curves\n",
    "    for i in range(len(diz.values())):\n",
    "       add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train_auto_brand.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
